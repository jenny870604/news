import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F
import torch

model_name = "./bert_models/roberta-news"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
label_map = {0: "ä¸­å¤®ç¤¾",1: "ä¸­æ¸¯æ¾³",2: "å…¬å…±æ”¿ç­–",3: "å…¬æ°‘é‹å‹•",4: "å“å‘³ç”Ÿæ´»",
            5: "åœ‹å…§",6: "åœ‹éš›",7: "æ”¿æ²»",8: "ç§‘æŠ€",9: "è©•è«–",10: "èª¿æŸ¥",11: "è²¡ç¶“",12: "é¢¨ç”Ÿæ´»"}

st.title("ğŸ“° æ–°èåˆ†é¡ Demo")
text = st.text_area("è«‹è¼¸å…¥ä¸€æ®µæ–°èæ–‡å­—")

if st.button("åˆ†é¡"):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=1)
        pred = torch.argmax(probs, dim=1).item()
    st.markdown(f"### â¡ï¸ åˆ†é¡çµæœï¼š**{label_map[pred]}**")
    st.markdown(f"ä¿¡å¿ƒåº¦ï¼š**{probs[0][pred].item():.2f}**")
